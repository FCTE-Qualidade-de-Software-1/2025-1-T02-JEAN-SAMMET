# 🌱 AgroMart - Projetar a avaliação


## 📘 Introdução

Com os objetivos e métricas definidos nas fases anteriores, esta **Fase 3** concentra-se na elaboração do **plano de avaliação**, estruturando:

- Níveis de pontuação e critérios de julgamento de cada métrica
- Instrumentos de coleta
- Procedimentos de execução
- Cronograma de atividades
- Responsabilidades da equipe avaliadora

Um plano bem estruturado assegura que a execução seja consistente, reprodutível e alinhada ao escopo proposto.

---

## 🎯 Objetivo

**Definir os níveis de pontuação e os critérios de julgamento** que permitam interpretar objetivamente os dados coletados e planejar a avaliação prática do software AgroMart.

---

## 🧩 Critérios de Julgamento e Níveis de Pontuação

A tabela abaixo apresenta, **para cada métrica**, a escala utilizada, os níveis de pontuação e o critério de aceitação:

---

### 🔹 Objetivo de Medição 1 – Compreensão dos Elementos Visuais

| ID   | Métrica                            | Escala         | Níveis de Pontuação                                  | Critério de Aceitação                                        |
|-------|------------------------------------|-----------------|-----------------------------------------------------|--------------------------------------------------------------|
| M1.1 | Taxa de Interpretação Correta      | Percentual (%)  | 0–69 = Ruim<br>70–89 = Regular<br>≥90 = Bom         | ≥90% de acertos em ícones críticos                          |
| M1.2 | Tempo de Hesitação por Ícone       | Segundos (s)    | >10 = Ruim<br>5–10 = Regular<br><5 = Bom            | Média inferior a 5 segundos                                 |
| M1.3 | Associação Correta de Cores        | Binário         | 0 = Incorreto<br>1 = Correto                        | 100% de associações corretas                                |
| M2.1 | Percepção de Utilidade Visual      | Likert (1–5)    | ≤2 = Ruim<br>3 = Regular<br>≥4 = Bom                | Média superior a 4.0                                         |
| M2.2 | Eficiência do Caminho da Tarefa    | Razão           | >1.5 = Ruim<br>1.2–1.5 = Regular<br>≤1.2 = Bom      | Razão menor ou igual a 1.2                                   |
| M3.1 | Taxa de Erro por Confusão Visual   | Ocorrências     | ≥3 = Ruim<br>2 = Regular<br>≤1 = Bom                | No máximo 1 erro por tarefa crítica                         |
| M3.2 | Matriz de Confusão de Ícones       | Frequência      | Pares com alta frequência (>30%) = Ruim            | Nenhum par deve ser fonte primária de confusão              |

---

### 🔹 Objetivo de Medição 2 – Clareza dos Feedbacks

| ID   | Métrica                            | Escala         | Níveis de Pontuação                                  | Critério de Aceitação                                        |
|-------|------------------------------------|-----------------|-----------------------------------------------------|--------------------------------------------------------------|
| M4.1 | Taxa de Percepção de Feedback      | Percentual (%)  | 0–79 = Ruim<br>80–94 = Regular<br>≥95 = Bom         | ≥95% identificam feedback                                   |
| M5.1 | Taxa de Compreensão das Mensagens  | Percentual (%)  | 0–79 = Ruim<br>80–89 = Regular<br>≥90 = Bom         | ≥90% de compreensão correta                                 |
| M6.1 | Tempo de Recuperação de Erro       | Segundos (s)    | >15 = Ruim<br>6–15 = Regular<br>≤5 = Bom            | Tempo médio baixo indica feedback eficaz                   |
| M6.2 | Avaliação da Utilidade do Feedback | Likert (1–5)    | ≤2 = Ruim<br>3 = Regular<br>≥4 = Bom                | Média superior a 4.2                                        |

---

## 🛠 Instrumentos de Coleta de Dados

- **Formulários Digitais ou Impressos:** Questionários pós-tarefa e pós-teste
- **Cronômetro:** Medição de tempos de hesitação e recuperação
- **Software de Gravação de Tela:** Registro dos fluxos de interação (com consentimento)
- **Planilhas de Observação:** Registro manual de erros e confusões
- **Tabelas de Frequência:** Compilação de matrizes de confusão

---

## 🧮 Procedimentos de Execução

1. **Briefing inicial ao participante**
   - Apresentar o objetivo do estudo
   - Solicitar consentimento para gravação
2. **Execução das tarefas**
   - Cenários pré-definidos (cadastrar produto, confirmar pedido, montar cesta)
   - Observador cronometra e registra respostas
3. **Aplicação de questionários pós-tarefa**
   - Coleta de percepções e avaliações Likert
4. **Encerramento**
   - Agradecimento e esclarecimento de dúvidas

---

## 🕒 Cronograma de Avaliação

| Data        | Atividade                              |
|-------------|----------------------------------------|
| a definir | Preparação do ambiente e materiais    |
| a definir | Execução dos testes com participantes |
| a definir  | Consolidação dos dados                |
| a definir | Análise e consolidação dos resultados |
| a definir  | Apresentação dos resultados finais    |

--- 

## 👥 Tabela de Contribuição

| 🎓 Matrícula | 🙋 Nome completo | 📊 Contribuição (%) |
|-------------|------------------|---------------------|
| 211030765 | [Guilherme Storch de Oliveira](https://github.com/storch7) | 16.66 |
| 222037610 | [Gabriel Lima da Silva](https://github.com/gabriel-lima258) | 16.66 |
| 222022000 | [Milena Fernandes Rocha](https://github.com/MilenaFRocha) | 16.66 |
| 222025324 | [João Lucas Araujo Siqueira](https://github.com/jlucasiqueira) | 16.66 |
| 222015248 | [Rafael Gomes Pereira](https://github.com/rafgpereira) | 16.66 |
| 222015112 | [Gabriel Reis Scheidt Paulino](https://github.com/Gxaite) | 16.66 |

---


## 📅 Histórico de Versões

| 📌 Versão | 📆 Data | ✍️ Descrição | 👤 Autor | 🔍 Revisor |
|:--------:|:-------|:-------------|:--------|:-----------:|
|`1.0`| 26/06/2025| Criação da documentação |[Gabriel Lima](https://github.com/gabriel-lima258)| [Guilherme Storch](https://github.com/storch7) |
